{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Code explaining lab_1.py \n",
    "## 1.1 faza testów 02.10.2024 22:99\n",
    "\n",
    "Przed eksperymentem sprawdzałem model na danych losowych, liczyło się dla mnie jedynie czy  model działa (uruchamia się) i czy 'coś' z niego wychodzi. ![zdjęcie 1](image1.png) to był wykres dany po wylosowaniu 1szego zestawu danych.\n",
    "```python\n",
    "# Generowanie losowych danych\n",
    "np.random.seed(42)  # Ustawienie ziarna losowości\n",
    "num_samples = 1000 # Liczba próbek\n",
    "\n",
    "# Generowanie losowych temperatur (270-400K) i zmian objętości (0.1-1.0)\n",
    "temperatures = np.random.uniform(270, 400, num_samples)\n",
    "delta_volumes = np.random.uniform(0.1, 1.0, num_samples)\n",
    "```\n",
    "wszystko bazowało na całkowicie losowych danych niezgodnych z realnymi pomiarami wiec nie ma co sie dziwić ze otrzymane informacje nie pozwalały na stwierdzenie niczego wiecej jak \"no działa\". \n",
    "![zdjęcie 2](image2.png)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Mój kod. \n",
    "Na tym etapie będe tłumaczył krok po kroku jak zbudowany jest mój kod i w jaki sposób będe go wykoprzystywał. Staram się by było jak naprościej ale jestem świadomy że jakaś minimalna wiedza z programowania w python jest potrzebna \n",
    "## 1.2 Import bibliotek"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tutaj jedynie przywołujemy najpotrzebniejsze biblioteki i zapisujemy je w po przywołaniu w kodzie nie musieć pisać całych nazw a jedynie skróty tj. `nn`, `pd` itd. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.2 Importowanie danych z pliku xlsx\n",
    "Obok zapisu `.csv`, `.xlsx` jest podstawowym i standardowym zapisem plików excel. Ale w przeciwieństwie do `.csv` możemy importować wartości z kolumn (np.temperature) a nie musimy zapisywać danych w jednej kolumn i oddzielać jej przecinkami tak jak by muisiało to być w pliku `.csv`. \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   temperature  delta_volume\n",
      "0   318.690215      0.972626\n",
      "1   393.592860      0.797620\n",
      "2   365.159212      0.945549\n",
      "3   347.825603      0.905345\n",
      "4   290.282423      0.638110\n"
     ]
    }
   ],
   "source": [
    "# 0. Otwieranie danych\n",
    "file_path = 'lab_1_dane.xlsx'\n",
    "# Sprawdzenie, czy plik istnieje\n",
    "if os.path.exists(file_path):\n",
    "    # odczytanie danych z arkusza \n",
    "    df = pd.read_excel(file_path, sheet_name='Sheet1')\n",
    "    print(df.head())\n",
    "else:\n",
    "    print(f\"Plik {file_path} nie istnieje. Upewnij się, że plik znajduje się w odpowiednim folderze.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nie ma tu dużo do tłumacznia ale i tak postaram się zapisać najważniejsze informacje tak dla przypomnienia ;). \n",
    "- `file_path` - zapisujemy ścieżkę naszego pliku z którego bierzemy dane. Ważne że gdy plik znajduje się w tym samym folderze co kod, nie musimy niż więcej dopisywać po za nazwą. \n",
    "- tutaj wykonujemy polecenie by program sprawdził czy dany plik w danym miejscu istnieje\n",
    "    ```python\n",
    "    if os.path.exists(file_path):\n",
    "    ```\n",
    "\n",
    "    - Jeśli plik został znaleziony, sprawdzamy czy dane zostaly wczytane poprawnie. do tego używamy `.head()` ta funkcja wyciąga 5 pierwszym elementów z naszego pliku. \n",
    "        ```python\n",
    "        df = pd.read_excel(file_path, sheet_name='Sheet1')\n",
    "        # w zmiennej df zapisujemy nasze informacje z pliku `lab_1_dane.xlsx`\n",
    "        print(df.head())\n",
    "        ```\n",
    "    - Jeśli plik nie został znaleziony wyskoczy nam informacje zwrotna:\n",
    "        ```python\n",
    "        else:\n",
    "        print(f\"Plik {file_path} nie istnieje. Upewnij się, że plik znajduje się w odpowiednim folderze.\")\n",
    "        ```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.2 Zapisywanie danych jako zmienne i ich konwersja na tensory. \n",
    "Teraz jak już mamy otworzone dane w zmiennej możemy rozdzielić je na wynyki pomiaru tempreatury z kolumny `temperature` i zmiany objętości z kolumny `delta_volume`. \n",
    "### 2.2.1 Wyciąganie danych"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Przykładowe dane: temperatury (T) i odpowiadające im zmiany objętości (delta_V)\n",
    "temperatures = df['temperature'].values  # Temperatura w Kelvinach\n",
    "delta_volumes = df['delta_volume'].values  # Zmiana objętości\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Przykładowo w zmiennej `temperatures` chcemny zapisać pomiary temperatury które aktualnie znajdują się w zmiennej `df` by to zrobić musimy wskazać jak się nazywa kolumna pod którą są szukane przez nas wartości. \n",
    "W tym przypadku jest to `temperatures` więc całość kodu wygląda następująco\n",
    "```python\n",
    "nasza_nowa_zmienna = zmienna_z_wszyskim['nazwa_szukanej_kolumny'].values \n",
    "#bo potrzebujemy wartości z tej kolumny. \n",
    "```\n",
    "\n",
    "```python\n",
    "temperatures = df['temperature'].values  # Temperatura w Kelvinach\n",
    "```\n",
    "\n",
    "I analogicznie lecimy dalej w celu \"wyciągniecia\" wszystkich potrzebnych przez nas informacji. \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2.2 Zapisywanie danych jako tensory. \n",
    "By użyć biblioteki `pytorch` do budowania modelu sieci neuronowej. Najpierw sobie trzeba wytłumaczyć \"po co to komu ten tensor?\"\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.2.2.BONUS  po co to komu ten tensor?\n",
    "Tensor to wielowymiarowa tablica danych, która jest uogólnieniem skalara, wektora i macierzy, taka macierz 3d (ale może mieć więcej niż 3 wymiary.)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Przykłady tensorów:\n",
    "- Skalar: Tensor zerowego rzędu, pojedyncza liczba. $x \\in \\mathbb{R}$\n",
    "- Wektor: Tensor pierwszego rzędu, jednowymiarowa tablica. $\\mathbf{x} \\in \\mathbb{R}^n$ \n",
    "- Macierz: Tensor drugiego rzędu, dwuwymiarowa tablica. $\\mathbf{X} \\in \\mathbb{R}^{m \\times n}$ \n",
    "- Tensor wyższego rzędu: Wielowymiarowa tablica.  $\\mathcal{X} \\in \\mathbb{R}^{d_1 \\times d_2 \\times \\ldots \\times d_k}$ \n",
    "\n",
    "```python\n",
    "import torch\n",
    "# Skalar\n",
    "scalar = torch.tensor(3.14)\n",
    "# Wektor\n",
    "vector = torch.tensor([1.0, 2.0, 3.0])\n",
    "# Macierz\n",
    "matrix = torch.tensor([[1.0, 2.0], [3.0, 4.0]])\n",
    "# Tensor trzeciego rzędu\n",
    "tensor = torch.tensor([[[1.0, 2.0], [3.0, 4.0]], [[5.0, 6.0], [7.0, 8.0]]])\n",
    "print(\"Scalar:\", scalar)\n",
    "print(\"Vector:\", vector)\n",
    "print(\"Matrix:\", matrix)\n",
    "print(\"Tensor:\", tensor)\n",
    "```\n",
    "\n",
    "**Dlaczego tensory są ważne?**\n",
    "- Wielowymiarowość: Tensory mogą reprezentować dane w wielu wymiarach, co jest kluczowe w modelowaniu złożonych struktur danych.\n",
    "- Operacje algebraiczne: Tensory umożliwiają wykonywanie operacji algebraicznych, takich jak iloczyn tensorowy, które są fundamentalne w algorytmach uczenia maszynowego.\n",
    "- Efektywność obliczeniowa: Biblioteki takie jak TensorFlow i PyTorch są zoptymalizowane do pracy z tensorami, co pozwala na szybkie i efektywne przetwarzanie danych na GPU.\n",
    "- Automatyczne różniczkowanie: Tensory są używane do obliczania gradientów w procesie optymalizacji i minimalizowania błędu predykcji modelu. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
